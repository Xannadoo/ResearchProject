model:
    pretrained_model_name_or_path: allenai/OLMo-7B-0724-Instruct-hf
    gradient_checkpointing: true
    use_cache: false

training:
  optimizer:
    type: AdamW
    parameters:
      lr: 5e-5
      weight_decay: 0.01
  scheduler:
    type: linear
    parameters:
      warmup_steps: 1000
  batch_size: 8
  max_steps: 2000
  gradient_accumulation_steps: 8
  mixed_precision: fp16

data:
  paths:
    - "ResearchProject/train_token_ids.npy"
  label_mask_paths:
    - "Research/Project/train_labels.npy"

  validation:
    paths:
      - "ResearchProject/val_token_ids.npy"
    label_mask_paths:
      - "ResearchProject/val_labels.npy"
