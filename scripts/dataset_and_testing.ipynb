{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xannadoo/miniconda3/envs/cntf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe6f71fa5b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from classes import QCA\n",
    "import random\n",
    "import serpyco\n",
    "import re\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, LLMGradientAttribution, TextTokenInput\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import warnings\n",
    "# Ignore warnings due to transformers library\n",
    "warnings.filterwarnings(\"ignore\", \".*past_key_values.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Skipping this token.*\")\n",
    "\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "    model.to('cuda')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo, tokenizer = load_model(\"allenai/OLMo-1B-hf\")\n",
    "\n",
    "serializer = serpyco.Serializer(QCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '../data/extracted_questions.jsonl'\n",
    "qcas = [serializer.load(json.loads(x)) for x in open(FILENAME).read().split('\\n')[:-1]]\n",
    "random.Random(42).shuffle(qcas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change & change_q from Sagniks code\n",
    "change = {'first': 'last', \n",
    "          'earlier': 'later', \n",
    "          'younger': 'older', \n",
    "          'later': 'earlier', \n",
    "          'older': 'younger',\n",
    "          'more recently': 'earlier'}\n",
    "\n",
    "def make_prompt(C,Q):\n",
    "    prompt = f\"\"\"Context: {C} Question: {Q} Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def change_q(question):\n",
    "    for k, v in change.items():\n",
    "        if k in question:\n",
    "            return question.replace(k, v)\n",
    "        \n",
    "def make_reversed_qs(Q, A):\n",
    "    doc = nlp(Q)\n",
    "    ents = set()\n",
    "    for ent in doc.ents:\n",
    "        #print(ent.text, ent.start_char, ent.end_char, ent.label_) \n",
    "        if ent.text in Q and ent.label_ in ['PERSON','NORP','FAC','ORG','GPE', 'LOC', 'PRODUCT', 'EVENT','WORK_OF_ART','LAW','LANGUAGE'] :\n",
    "            ents.add(ent.text) \n",
    "    \n",
    "    #print(ents, Q, end = ' ')\n",
    "    ents = list(ents)\n",
    "    if len(ents)==2:\n",
    "        if ents[0] in ents[1] or ents[1] in ents[0]:\n",
    "            return None, None\n",
    "        elif ents[0] in A:\n",
    "            #print('accepted')\n",
    "            A2 = ents[1]\n",
    "        elif ents[1] in A:\n",
    "            #print('accepted')\n",
    "            A2 = ents[0]\n",
    "        else:\n",
    "            #print('failed')\n",
    "            return None, None\n",
    "        Q2 = change_q(Q)\n",
    "        return Q2, A2\n",
    "\n",
    "    else:\n",
    "        #print('failed')\n",
    "        return None,None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates the dataset for the later experiments\n",
    "new = False\n",
    "if new:\n",
    "    c = 0\n",
    "    k = 0\n",
    "    prompts = {}\n",
    "    for data in qcas[:]:    \n",
    "        Q, C, A = data.question.text, data.context.text, data.answer_texts_orig[0]\n",
    "        Q2, A2 = make_reversed_qs(Q, A)\n",
    "\n",
    "        if Q2 != None:\n",
    "            c+=1\n",
    "            # print(Q, A)\n",
    "            # print(Q2, A2)\n",
    "            prompt = make_prompt(C, Q)\n",
    "            prompt_2 = make_prompt(C, Q2)\n",
    "            prompts[data.id] = {'prompt_o': prompt, 'gold_o': A, \n",
    "                                'prompt_s': prompt_2, 'gold_s': A2}\n",
    "\n",
    "        else:\n",
    "            k+=1\n",
    "\n",
    "    print(f'{c}, {k}, {c/(c+k):.2%}')\n",
    "    with open('../data/prepped_questions.json', 'w') as fp:\n",
    "        fp.write(json.dumps(prompts))\n",
    "\n",
    "p = [json.loads(x) for x in open('../data/prepped_questions.json').read().split('\\n')][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and testing of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Ainhoa Artolazábal Royo( born 6 March 1972) is a road cyclist from Spain. She represented her nation at the 1992 Summer Olympics in the women's road race. Allen Holden( 18 April 1911 – 12 December 1980) was a New Zealand cricketer. He played two first- class matches for Otago between 1937 and 1940. Question: Who was born earlier, Allen Holden or Ainhoa Artolazábal? Answer:\n",
      "Allen Holden\n",
      "Context: Ainhoa Artolazábal Royo( born 6 March 1972) is a road cyclist from Spain. She represented her nation at the 1992 Summer Olympics in the women's road race. Allen Holden( 18 April 1911 – 12 December 1980) was a New Zealand cricketer. He played two first- class matches for Otago between 1937 and 1940. Question: Who was born later, Allen Holden or Ainhoa Artolazábal? Answer:\n",
      "Ainhoa Artolazábal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in p.items():\n",
    "    prompt = v['prompt_o']\n",
    "    print(v['prompt_o'])\n",
    "    print(v['gold_o'])\n",
    "    ans = v['gold_o']\n",
    "    print(v['prompt_s'])\n",
    "    print(v['gold_s'])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allen Holden was born in 1931, while A\n",
      "******************************\n",
      "Context: Ainhoa Artolazábal Royo( born 6 March 1972) is a road cyclist from Spain. She represented her nation at the 1992 Summer Olympics in the women's road race. Allen Holden( 18 April 1911 – 12 December 1980) was a New Zealand cricketer. He played two first- class matches for Otago between 1937 and 1940. Question: Who was born earlier, Allen Holden or Ainhoa Artolazábal? Answer: Allen Holden was born in 1931, while A\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False)\n",
    "inputs.to(olmo.device)\n",
    "response = olmo.generate(**inputs, max_new_tokens=10, do_sample=True, top_k=50, top_p=0.95)\n",
    "output = tokenizer.batch_decode(response, skip_special_tokens=True)[0].split('\\n')[0]\n",
    "out = re.findall(r'(?<=Answer: ).*', output)[0]\n",
    "\n",
    "print(out)\n",
    "print('*'*30)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing counterfactual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(data):\n",
    "    prompt = data['prompt_o']\n",
    "    A = ' ' + data['gold_o']\n",
    "\n",
    "    prompt2 = data['prompt_s']\n",
    "    A2= ' ' + data['gold_s']\n",
    "\n",
    "    #remove words in common\n",
    "    com = set(A.split()) & set(A2.split())\n",
    "\n",
    "    A_ = ' '.join([word for word in A.split() if word not in com])\n",
    "    A2_ = ' '.join([word for word in A2.split() if word not in com])\n",
    "\n",
    "    if len(A_) < 1 or len(A2_) < 1:\n",
    "        print('not possible due to common answer strings')\n",
    "        return A, [], A2, []\n",
    "    else:\n",
    "        A = A_\n",
    "        A2 = A2_\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False)\n",
    "    inputs.to(olmo.device)\n",
    "    response = olmo.generate(**inputs, max_new_tokens=10, do_sample=True, top_k=50, top_p=0.95)\n",
    "    \n",
    "    inputs2 = tokenizer(prompt2, return_tensors='pt', return_token_type_ids=False)\n",
    "    inputs2.to(olmo.device)\n",
    "    response2 = olmo.generate(**inputs2, max_new_tokens=10, do_sample=True, top_k=50, top_p=0.95)\n",
    "\n",
    "    output = tokenizer.batch_decode(response, skip_special_tokens=True)[0].split('\\n')[0]\n",
    "    output2 = tokenizer.batch_decode(response2, skip_special_tokens=True)[0].split('\\n')[0]\n",
    "\n",
    "    out = re.findall(r'(?<=Answer: ).*', output)[0]\n",
    "    out2 = re.findall(r'(?<=Answer: ).*', output2)[0]\n",
    "\n",
    "    #check if gold is in output:\n",
    "    gold_present = False\n",
    "    for i in A.split():\n",
    "        #print(f'checking {i} in {out}')\n",
    "        if i in out:\n",
    "            gold_present = True\n",
    "    \n",
    "    #also check if the wrong answer is present:\n",
    "    wrong_present = False\n",
    "    for i in A2.split():\n",
    "        if i in out:\n",
    "            wrong_present = True\n",
    "\n",
    "    #SAme for the counterfactual\n",
    "    #check if gold is in output:\n",
    "    gold2_present = False\n",
    "    for i in A2.split():\n",
    "        if i in out2:\n",
    "            gold2_present = True\n",
    "    \n",
    "    #also check if the wrong answer is present:\n",
    "    wrong2_present = False\n",
    "    for i in A.split():\n",
    "        if i in out2:\n",
    "            wrong2_present = True\n",
    "\n",
    "    print('*'*30)\n",
    "    print(f'Output: {out}\\nTrue: {A}\\ngold in output: {gold_present}, \\nwrong in output: {wrong_present}')\n",
    "    print('*'*30)\n",
    "    print(f'Output: {out2}\\nTrue: {A2}\\ngold in output: {gold2_present}, \\nwrong in output: {wrong2_present}')\n",
    "    print('*'*30)\n",
    "    return A, out, A2, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not possible due to common answer strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(' Bob Jones', [], ' Bob', [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## testing if the regex can identify when it is not able to seperate the answers due to overlapping tokens\n",
    "#This is not a prompt in the dataset, but a test case\n",
    "sam = {'prompt_o': 'Context: Bob Jones is a large tiger, weighing 100kg. Bob is a small housecat, weighing 5kg. Question: Which creature is bigger, Bob or Bob Jones? Answer:',\n",
    "        'gold_o': 'Bob Jones',\n",
    "        'prompt_s': 'Context: Bobby is a large tiger, weighing 100kg. Bob is a small housecat, weighing 5kg. Question: Which creature is smaller, Bob or Bobby? Answer:',\n",
    "        'gold_s': 'Bob'}\n",
    "\n",
    "get_responses(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Ainhoa Artolazábal Royo( born 6 March 1972) is a road cyclist from Spain. She represented her nation at the 1992 Summer Olympics in the women's road race. Allen Holden( 18 April 1911 – 12 December 1980) was a New Zealand cricketer. He played two first- class matches for Otago between 1937 and 1940. Question: Who was born earlier, Allen Holden or Ainhoa Artolazábal? Answer:\n",
      "Allen Holden\n",
      "Context: Ainhoa Artolazábal Royo( born 6 March 1972) is a road cyclist from Spain. She represented her nation at the 1992 Summer Olympics in the women's road race. Allen Holden( 18 April 1911 – 12 December 1980) was a New Zealand cricketer. He played two first- class matches for Otago between 1937 and 1940. Question: Who was born later, Allen Holden or Ainhoa Artolazábal? Answer:\n",
      "Ainhoa Artolazábal\n",
      "******************************\n",
      "Output: Ainhoa Artolazábal was born\n",
      "True: Allen Holden\n",
      "gold in output: False, \n",
      "wrong in output: True\n",
      "******************************\n",
      "Output: Ainhoa Artolazábal.\n",
      "True: Ainhoa Artolazábal\n",
      "gold in output: True, \n",
      "wrong in output: False\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for k, v in p.items():\n",
    "    print(v['prompt_o'])\n",
    "    print(v['gold_o'])\n",
    "    print(v['prompt_s'])\n",
    "    print(v['gold_s'])\n",
    "    A, out, A2, out2 = get_responses(v)\n",
    "    prompt = v['prompt_o']\n",
    "    prompt2 = v['prompt_s']\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing IG setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(olmo, olmo.model.embed_tokens)\n",
    "\n",
    "llm_attr = LLMGradientAttribution(lig, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "inp = TextTokenInput(\n",
    "    prompt, \n",
    "    tokenizer)\n",
    "\n",
    "attr_res = llm_attr.attribute(inp, target=A, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0095e-01,  2.2834e-01,  2.5809e-01,  9.4263e-03, -1.2829e-01,\n",
       "        -2.6281e-02,  7.4866e-02, -1.5062e-01, -1.6051e-01, -4.0247e-01,\n",
       "        -1.4261e-01,  2.2532e-01, -4.8324e-01,  4.0915e-02, -7.7648e-02,\n",
       "         6.3888e-02, -1.3712e-01, -2.6419e-01,  7.1528e-02,  1.4301e-01,\n",
       "        -1.6980e-01, -1.0219e-01, -4.5196e-02, -6.2250e-02, -5.8290e-02,\n",
       "         1.2788e-02, -1.4649e-01, -3.4580e-01, -2.2122e-01, -1.2986e-01,\n",
       "        -2.8436e-01,  1.2015e-02, -3.8794e-01, -2.5551e-01, -1.2745e-01,\n",
       "        -2.8330e-01,  8.8779e-01, -1.7755e-01,  1.3934e-02, -1.3257e-01,\n",
       "        -6.1719e-02,  9.9318e-02,  1.5143e-01, -4.4190e-01,  2.2799e-02,\n",
       "        -6.4878e-01, -3.8206e-01, -3.4850e-01, -3.0787e-01, -6.0695e-01,\n",
       "        -2.6879e-01, -8.7466e-02, -3.5023e-02, -4.2118e-01,  1.8115e-01,\n",
       "         4.8309e-02, -1.4970e-01, -2.7419e-01, -8.4801e-01,  1.7807e-03,\n",
       "        -3.0186e-01, -2.5029e-01, -5.5942e-01, -6.1979e-01, -3.4861e-01,\n",
       "         3.2986e-01, -5.0454e-01, -3.9974e-01,  7.3702e-02, -5.2059e-01,\n",
       "        -5.1006e-01, -5.5768e-01, -4.5537e-01, -2.1800e-01, -2.4029e-01,\n",
       "        -7.8279e-01, -8.7624e-02,  6.6950e-01,  2.1779e+00,  5.6933e-01,\n",
       "        -4.5992e-01, -3.9706e-01,  4.5097e-01,  2.5192e-01,  1.5216e-01,\n",
       "         8.5324e-01,  8.1359e-01,  1.6785e+00,  6.4836e-01,  1.3902e+00,\n",
       "         1.0715e+00,  7.3058e-01,  7.4327e-01,  1.4055e+00,  5.6787e-01,\n",
       "         3.6006e+00, -3.8656e+00,  1.9493e+00], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_res.seq_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = TextTokenInput(\n",
    "    prompt2, \n",
    "    tokenizer)\n",
    "\n",
    "attr_res_p = llm_attr.attribute(inp, target=A2, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.1368e+00, -4.4702e+00, -2.1726e+00,  3.5410e+00,  1.9846e+00,\n",
       "         2.3632e+00,  1.2595e+00,  2.4721e-01, -9.0822e-02, -8.3981e-01,\n",
       "        -8.5783e-01, -3.7816e+00, -4.6816e+00, -2.2036e+00, -3.7384e+00,\n",
       "        -1.4703e+00, -1.6081e+00, -2.6866e+00, -9.9208e-01, -7.2031e-01,\n",
       "        -1.8597e+00, -8.2290e-01, -7.6748e-01, -7.7432e-01, -2.3317e-01,\n",
       "         8.4931e-01, -3.2089e-01,  5.2609e-01,  1.7468e+00, -8.5709e-01,\n",
       "         1.2519e+00,  1.5814e+00,  2.3737e+00,  2.1286e+00, -1.3301e+00,\n",
       "         4.1507e+00, -1.2378e+01, -2.1280e-01, -1.7145e-02, -1.4512e-01,\n",
       "         1.8608e-01,  3.2113e-01, -1.3170e-01,  7.3654e-01,  4.8685e-01,\n",
       "        -5.3038e-01,  5.7268e-03,  6.8341e-02, -1.2454e-01,  4.5491e-02,\n",
       "        -2.8191e-03,  1.6675e-01,  1.2444e-01, -3.7403e-01, -1.7114e-01,\n",
       "        -2.5496e-01, -2.1321e-01,  3.6985e-02,  6.8771e-01,  5.9305e-01,\n",
       "        -2.0475e-01, -5.2510e-01, -4.4681e-01,  8.0246e-02,  3.6689e-02,\n",
       "         6.1013e-01,  2.7245e-01,  1.8514e-01,  3.7314e-01,  2.1000e+00,\n",
       "         1.1934e+00,  3.5522e-01, -3.9168e-01, -6.8100e-01, -4.3197e-01,\n",
       "        -2.2441e+00,  6.3666e-01,  1.1775e+00,  2.1714e+00,  3.7835e-01,\n",
       "         5.0791e-02,  1.0067e-01,  4.5587e-01,  3.1157e-01,  1.0733e+00,\n",
       "        -5.9672e-02, -3.2162e-01,  2.4730e+00,  5.0524e+00,  3.4487e+00,\n",
       "         6.2437e+00,  1.7415e+00,  2.1139e+00,  4.5788e+00,  2.8960e+00,\n",
       "         4.3880e-01, -3.5405e+00, -6.1157e+00], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_res_p.seq_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cntf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
