#!/bin/bash
#SBATCH --job-name=olmo_finetune
#SBATCH --output=logs/%x_%j.out
#SBATCH --error=logs/%x_%j.err
#SBATCH --time=24:00:00
#SBATCH --partition=acltr
#SBATCH --gres=gpu:A100:4            
#SBATCH --cpus-per-task=16


hostname

# Load modules
module load Anaconda3/2024.02-1

# Activate the conda environment
source activate captum_test

# Change to the directory containing your training script
cd /ResearchProject

# Run the torchrun command for distributed training
torchrun --nproc_per_node=4 train.py --config training.yaml --dry-run
